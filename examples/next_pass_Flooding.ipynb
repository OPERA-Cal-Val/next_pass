{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "924d71a0-75bd-44ff-9393-773f54cec7af",
   "metadata": {},
   "source": [
    "# Example of next_pass Application to a Flooding Event (May 2024, Porto Algre, Brazil)\n",
    "\n",
    "## Background\n",
    "* Knowing the time of a satellite overpass (OP) at a precise location is crucial to plan and prepare disaster impact studies. \n",
    "The script below can be used to predict the overpasses of the Landsat 8 & 9 and Sentinel 1 & 2 satellites over a  selected location. For Landsat 8 this occurs every 16 days and for Sentinel 2A / 2B this occurs every 10 days.\n",
    "\n",
    "* The code calls the Python package 'next_pass' located at https://github.com/ehavazli/next_pass. The latter predicts the next overpass of the satellite of interest by scanning the relevant acquisition plans:\n",
    "\t- Landsat acquisition plans (json files) : https://landsat.usgs.gov/sites/default/files/landsat_acq/assets/json/cycles_full.json\n",
    "\t- Sentinel acquisition plans (KML files to import to Google Earth Pro) : https://sentinel.esa.int/web/sentinel/copernicus/sentinel-1/acquisition-plans\n",
    "      \n",
    "\n",
    "* This specific notebook showcases the application of the next_pass tool to a May 2024 flooding event in the Porto Algre, Brazil \n",
    "\n",
    "## Tool Description\n",
    "\n",
    "All what a user needs to provide is the precise location for which he desires to identify the next overpasses. The location can be inputted as (latitude, longitude) or as the name of the city of interest. The script returns the next collect for Sentinel-1 and Sentinel-2 and the next passes, in ascending and descending directions separately, for Landsat-8 and Landsat-9:\n",
    "\n",
    "- Specify a location \n",
    "- Run find_next_overpass for Sentinel-1, Sentinel-2 and the Landsats (8&9) \n",
    "- Visualize each of the above predicted overpass \n",
    "\n",
    "The outputs of next_pass can be compared against overpasses of the site you are interested in using the ESA Orbital Prediction and Overpass Tool (OPOT) at https://evdc.esa.int/orbit/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a463e75-447f-4aa9-99bc-3e5d977a59aa",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run the overpass predictor with the given location, run all cells in the notebook starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dbae5-6831-4634-a722-74897b93cba3",
   "metadata": {},
   "source": [
    "### Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee013c33-33b6-49dd-a7b6-1936ef55e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to Python's path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "    \n",
    "import next_pass\n",
    "import utils\n",
    "import folium\n",
    "import re  # Import regular expressions\n",
    "import random  # To generate random colors\n",
    "import earthaccess\n",
    "import leafmap\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import boto3\n",
    "import rasterio\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "from shapely.geometry import Point, Polygon, shape, box\n",
    "from geopy.geocoders import Nominatim\n",
    "from argparse import Namespace\n",
    "from datetime import datetime\n",
    "from rasterio.session import AWSSession\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2eedcf-c095-4572-87d3-eff8ed249209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "\n",
    "# Style function for the bounding box GeoJSON layer\n",
    "def style_function(feature):\n",
    "    return {\n",
    "        'fillColor': '#808080',  # Gray fill color\n",
    "        'color': '#000000',       # Black border color\n",
    "        'weight': 4,              # Thicker border (increased thickness)\n",
    "        'fillOpacity': 0.3        # Fill opacity (adjust if needed)\n",
    "    }\n",
    "# Function to generate random hex color\n",
    "def random_color():\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "# Function to print text with color in console (ANSI escape code)\n",
    "def print_colored_text(text, color):\n",
    "    # Escape sequence for colored text\n",
    "    print(f\"\\033[38;2;{color[0]};{color[1]};{color[2]}m{text}\\033[39m\")\n",
    "\n",
    "# \n",
    "def hsl_distinct_colors(n):\n",
    "    colors = []\n",
    "    for i in range(n):\n",
    "        # Generate colors with different hues\n",
    "        hue = i / float(n)  # Hue ranges from 0 to 1\n",
    "        color = colorsys.hsv_to_rgb(hue, 1.0, 1.0)  # Convert HSL to RGB\n",
    "        # Convert from RGB (0-1) to hex (#RRGGBB)\n",
    "        rgb = [int(c * 255) for c in color]\n",
    "        hex_color = \"#{:02x}{:02x}{:02x}\".format(*rgb)\n",
    "        colors.append(hex_color)\n",
    "    return colors\n",
    "\n",
    "def spread_rgb_colors(n):\n",
    "    colors = []\n",
    "    step = 255 // n  # Divide the color space into n parts\n",
    "    for i in range(n):\n",
    "        # Spread out the color values across the RGB spectrum\n",
    "        r = (i * step) % 256\n",
    "        g = ((i + 1) * step) % 256\n",
    "        b = ((i + 2) * step) % 256\n",
    "        hex_color = \"#{:02x}{:02x}{:02x}\".format(r, g, b)\n",
    "        colors.append(hex_color)\n",
    "    return colors\n",
    "\n",
    "def hsl_distinct_colors_improved(num_colors):\n",
    "    colors = []\n",
    "    \n",
    "    for i in range(num_colors):\n",
    "        # Set Hue (H) to a random value, excluding extremes like 0° (red) and 60° (yellow)\n",
    "        hue = (i * 360 / num_colors) % 360\n",
    "        \n",
    "        # Set Saturation (S) to a high value (e.g., 70%) for vivid colors\n",
    "        saturation = random.randint(60, 80)  # Avoid dull colors\n",
    "        \n",
    "        # Set Lightness (L) to a lower value to avoid bright, light colors like yellow (range 30-50%)\n",
    "        lightness = random.randint(30, 50)  # Darker or neutral colors\n",
    "\n",
    "        # Convert HSL to RGB using the colorsys library\n",
    "        r, g, b = colorsys.hls_to_rgb(hue / 360, lightness / 100, saturation / 100)\n",
    "\n",
    "        # Convert RGB to hex format (RGB values are in [0, 1], so multiply by 255)\n",
    "        hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r * 255), int(g * 255), int(b * 255))\n",
    "        colors.append(hex_color)\n",
    "    \n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c73e94-54be-4c2d-ab83-0b7fe432da99",
   "metadata": {},
   "source": [
    "### Specify location\n",
    "Start with selecting the location by  specifying the latitude/longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784914a-c997-4920-aaef-97ba570c2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floods near Porto Alegre, Brazil in 2024\n",
    "lon_W, lat_S, lon_E, lat_N = (-54.215, -30.766,-50.814, -28.938)\n",
    "location_file_path ='' # empty for this example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7867f1-e025-43eb-8357-6d57681d93b7",
   "metadata": {},
   "source": [
    "### Specify satellites of interest \n",
    "For now, the tool operates for Sentinel 1A and 2A and Landsat 8 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a15937-1d57-4772-8fff-eb277b23f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satellites\n",
    "sat1 = \"sentinel-1\"\n",
    "sat2 = \"sentinel-2\"\n",
    "sat3 = \"landsat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee41892-14ca-4aa5-85a5-8d84f70596cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the args object to pass to find_next_overpass\n",
    "args = Namespace(\n",
    "    bbox=(lat_S, lat_N, lon_W, lon_E),\n",
    "    aoi_file=location_file_path,  # assuming locationfile_path is defined\n",
    "    satellite=sat1  # assuming sat1 is defined (e.g., 'sentinel-1', 'sentinel-2', 'landsat')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af2db9-71be-48cd-acbf-1d62b4926d31",
   "metadata": {},
   "source": [
    "### Specify time interval \n",
    "The user can set a period for the retrieval of OPERA products if interested in a specific prior event. \n",
    "Note that, other than what is requested by the user, we display systematically all of the recent available OPERA data for the last month at the time the notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d58d4d-44d0-4edb-9a84-74b80d1393f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define a time period for the retrieval of OPERA products of interest for the flooding event\n",
    "PreEventDate=\"2024-04-21\"  #Pre-event date\n",
    "SynEventDate=\"2024-05-06\"  #Syn-event date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c7370e-cbfd-4eab-90ea-f2fe2a7d736c",
   "metadata": {},
   "source": [
    "### Run next_pass\n",
    "use next_pass to predict the overpasses of the above satellites over the selected location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75208e53-ee5c-434d-99ba-e23759121379",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** \",sat1,\" ***\")\n",
    "result1 = next_pass.find_next_overpass(args)\n",
    "# result1 is a dictionary \n",
    "s1_next_collect_info = result1.get(\"next_collect_info\", \"No collection info available\")\n",
    "s1_next_collect_geometry = result1.get(\"next_collect_geometry\", None)\n",
    "print(s1_next_collect_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6c21e-598b-4f0e-b593-4d89ecf167b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** \",sat2,\" ***\")\n",
    "args.satellite = sat2\n",
    "result2 = next_pass.find_next_overpass(args)\n",
    "s2_next_collect_info = result2.get(\"next_collect_info\", \"No collection info available\")\n",
    "s2_next_collect_geometry = result2.get(\"next_collect_geometry\", None)\n",
    "print(s2_next_collect_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597f45a-34e0-4026-9286-eaa4b6af52bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"*** \",sat3,\" ***\")\n",
    "args.satellite = sat3\n",
    "result3 = next_pass.find_next_overpass(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887dd39-d863-4606-9c53-ab02ed4b582c",
   "metadata": {},
   "source": [
    "### Overpasses Vizualisation  \n",
    "The below vizualization tool shows the path of a selected satellite at the predicted date/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d8f13-2f11-4110-a315-e7766ffa2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by choosing what satellite to visualize \n",
    "sat_to_visualize = 'Sentinel-1'; # can be Sentinel-1 or Sentinel-2\n",
    "\n",
    "if location_file_path:\n",
    "    area_polygon = utils.create_polygon_from_kml(location_file_path)\n",
    "    # Convert to a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame({'geometry': [area_polygon]}, crs=\"EPSG:4326\")  # WGS 84 CRS\n",
    "    # Create a Folium map centered at the bounding box centroid\n",
    "    m = folium.Map(location=[area_polygon.centroid.y, area_polygon.centroid.x], zoom_start=4)\n",
    "    # Add the bounding box as a GeoJSON layer\n",
    "    folium.GeoJson(gdf.to_json(), name=\"Area of interest\", style_function=style_function).add_to(m)\n",
    "elif lat_S == lat_N and lon_W == lon_E:\n",
    "    # Create the point\n",
    "    point = Point(lon_E, lat_N)\n",
    "\n",
    "    # Create a Folium map centered at the point location\n",
    "    m = folium.Map(location=[point.y, point.x], zoom_start=4)\n",
    "\n",
    "    # Add a cross-shaped marker to the map\n",
    "    folium.Marker(\n",
    "        location=[point.y, point.x],  # Latitude, Longitude\n",
    "        icon=folium.Icon(icon='glyphicon-remove', icon_color='red', prefix='glyphicon')  # Cross symbol with red color\n",
    "    ).add_to(m)\n",
    "else:\n",
    "    # Create the bounding box as a polygon\n",
    "    bounding_box = box(lon_W, lat_S, lon_E, lat_N)\n",
    "\n",
    "    # Convert to a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame({'geometry': [bounding_box]}, crs=\"EPSG:4326\")  # WGS 84 CRS\n",
    "\n",
    "    # Create a Folium map centered at the bounding box centroid\n",
    "    m = folium.Map(location=[bounding_box.centroid.y, bounding_box.centroid.x], zoom_start=4)\n",
    "    # Add the bounding box as a GeoJSON layer\n",
    "    folium.GeoJson(gdf.to_json(), name=\"Bounding Box\", style_function=style_function).add_to(m)\n",
    "\n",
    "if sat_to_visualize == 'Sentinel-1':\n",
    "    vi_next_collect_info = s1_next_collect_info\n",
    "    vi_next_collect_geometry = s1_next_collect_geometry\n",
    "elif sat_to_visualize == 'Sentinel-2':\n",
    "    vi_next_collect_info = s2_next_collect_info\n",
    "    vi_next_collect_geometry = s2_next_collect_geometry\n",
    "else:\n",
    "    vi_next_collect_info = l8_next_collect_info\n",
    "    vi_next_collect_geometry = l8_next_collect_geometry\n",
    "        \n",
    "print('\\n ** Visualizing overpasses for ',sat_to_visualize,' ** \\n')\n",
    "# Add each Polygon in next_collect_geometry\n",
    "lines = vi_next_collect_info.split(\"\\n\")\n",
    "# Clean lines by keeping only those that contain numbers (1-9)\n",
    "cleaned_info = [line for line in lines if re.search(r'[1-9]', line)]  # Line must contain digits (1-9)\n",
    "vi_next_collect_info_list = cleaned_info  # Now it's a list of strings (one per row in the table)\n",
    "num_polygons = len(vi_next_collect_geometry)\n",
    "num_info_lines = len(vi_next_collect_info_list)\n",
    "#print(num_polygons)\n",
    "#print(num_info_lines)\n",
    "\n",
    "# Use the HSL distinct colors function\n",
    "distinct_colors_list_1 = spread_rgb_colors(num_polygons)\n",
    "distinct_colors_list_2 = hsl_distinct_colors(num_polygons)\n",
    "distinct_colors_list_3 = hsl_distinct_colors_improved(num_polygons)\n",
    "\n",
    "if vi_next_collect_geometry:\n",
    "    for i, (polygon, info) in enumerate(zip(vi_next_collect_geometry, vi_next_collect_info_list), start=1):\n",
    "    #i=3 \n",
    "    #polygon =vi_next_collect_geometry[2]\n",
    "    #info = vi_next_collect_info_list[2]\n",
    "    \n",
    "        if isinstance(polygon, Polygon):  # Ensure it's a valid Polygon\n",
    "            # Get a distinct color for each polygon\n",
    "            color = distinct_colors_list_3[i - 1]\n",
    "    \n",
    "            # Print the info with corresponding color in the console\n",
    "            print_colored_text(f\"{info}\", tuple(int(color[i:i+2], 16) for i in (1, 3, 5)))\n",
    "    \n",
    "            \n",
    "            geojson_data = gpd.GeoSeries([polygon]).__geo_interface__\n",
    "            folium.GeoJson(\n",
    "                geojson_data, \n",
    "                name=\"Next Collect Area\",\n",
    "                style_function=lambda x, color=color: {\"color\": color, \"weight\": 2, \"fillOpacity\": 0.3},\n",
    "                popup=folium.Popup(f\"Polygon: {info}\", max_width=300)  # Display corresponding info line\n",
    "            ).add_to(m)\n",
    "\n",
    "print('')\n",
    "# Display the map and save to file\n",
    "m.save(\"bounding_box_map.html\")\n",
    "m  # If using Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2e25f-9536-499e-a60e-c9bcac90b800",
   "metadata": {},
   "source": [
    "# Available OPERA Products\n",
    "\n",
    "## Description\n",
    "* Here we will use Leafmap and Earthaccess to explore OPERA DSWx Products.\n",
    "* The Leafmap library provides a suite of tools for interactive mapping and visualization in Jupyter Notebooks. Leafmap version 0.30.0 and later offers tools specifically for accessing NASA Earthdata by building on the newly developed NASA Earthaccess library. Earthaccess provides streamlined access to NASA Earthdata and simplifies the authentication and querying process over previously developed approaches. \n",
    "* This section is designed to leverage tools within Earthaccess and Leafmap to facilitate easier access and visualization of OPERA data products for a user-specified area of interest (AOI). \n",
    "\n",
    "## OPERA DSWx Products \n",
    "\n",
    "The Dynamic Surface Water eXtent (DSWx) products map pixel-wise surface water detections using optical or SAR imagery. The DSWx suite is composed of complementary products, which are named according to their input datasets. In the present section, we will focus on: \n",
    "\n",
    "- DSWx from Harmonized Landsat Sentinel-2 (DSWx-HLS)\n",
    "- DSWx from Sentinel-1 (DSWx-S1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25921323-a971-4ac5-812d-a7282252bad8",
   "metadata": {},
   "source": [
    "## View the available OPERA products\n",
    "Note above that the `earthdata_df` contains a number of columns with metadata about each available product. the `ShortName` column will be used to produce a new dataframe containing only OPERA products. Let's view the available products and their metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64b90d-cb2d-40ae-b8a0-2d8925e11986",
   "metadata": {},
   "outputs": [],
   "source": [
    "### View Earthdata datasets\n",
    "earthdata_url = 'https://github.com/opengeos/NASA-Earth-Data/raw/main/nasa_earth_data.tsv'\n",
    "earthdata_df = pd.read_csv(earthdata_url, sep='\\t')\n",
    "opera_df = earthdata_df[earthdata_df['ShortName'].str.contains('OPERA', case=False)]\n",
    "### Print the available OPERA datasets \n",
    "print('Available OPERA datasets:', opera_df['ShortName'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc2314-500c-4e70-b628-86037f651da3",
   "metadata": {},
   "source": [
    "## Display all most recent OPERA products at the selected Area of Interest (AOI)\n",
    "* The script will use the area of interest (AOI) indicated above to predict overpasses to retreive all most recent OPERA products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68469ff5-e17c-4546-bbd4-7666947bd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell initializes the AOI.\n",
    "if location_file_path:\n",
    "    AOI = area_polygon.bounds\n",
    "else:\n",
    "    # Create the bounding box as a polygon\n",
    "    AOI = (lon_W, lat_S,lon_E, lat_N)\n",
    "print(AOI)\n",
    "c_lat = (AOI[1] + AOI[3]) / 2  # (miny + maxy) / 2\n",
    "c_lon = (AOI[0] + AOI[2]) / 2  # (minx + maxx) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeaf456-56bc-411b-ab68-a7a65473d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pre and Syn event dates in the last month\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "one_year_ago = date.today() - relativedelta(months=12)\n",
    "StartDate_Recent = one_year_ago.strftime(\"%Y-%m-%d\") + \"T00:00:00\"  \n",
    "EndDate_Recent = today.strftime(\"%Y-%m-%d\") + \"T23:59:59\" \n",
    "print(StartDate_Recent)\n",
    "print(EndDate_Recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0be0c-8fbc-477d-989d-0d53e787c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opera_datasets = opera_df['ShortName'].values\n",
    "# Dictionary to store results\n",
    "results_dict = {}\n",
    "\n",
    "# Iterate through each dataset\n",
    "for dataset in opera_datasets:\n",
    "    print(f\"🔍 Searching {dataset}...\")\n",
    "\n",
    "    try:\n",
    "        results, gdf = leafmap.nasa_data_search(\n",
    "            short_name=dataset,\n",
    "            cloud_hosted=True,\n",
    "            bounding_box=AOI,\n",
    "            temporal=(StartDate_Recent, EndDate_Recent),\n",
    "            #count=-1,\n",
    "            return_gdf=True,\n",
    "        )\n",
    "        gdf=gdf[-5:]\n",
    "        print(f\"✅ Success: {dataset} → {len(gdf)} granules found.\")\n",
    "        results_dict[dataset] = {\n",
    "            \"results\": results,\n",
    "            \"gdf\": gdf,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching {dataset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95235e-6617-4e0c-ab69-169e8cb6a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map(center=(c_lat, c_lon), zoom=7)\n",
    "m.add_basemap(\"Satellite\")\n",
    "\n",
    "num_items = len(results_dict.items())\n",
    "distinct_colors_list_items = hsl_distinct_colors_improved(num_items)\n",
    "\n",
    "for i, (dataset, data) in enumerate(results_dict.items()):\n",
    "    color = distinct_colors_list_items[i - 1]\n",
    "    if not data[\"gdf\"].empty:\n",
    "        print_colored_text(f\"{dataset}\", tuple(int(color[i:i+2], 16) for i in (1, 3, 5)))\n",
    "        style = {\"color\": color, \"fillColor\": color, \"weight\": 2, \"fillOpacity\": 0.5}\n",
    "        m.add_gdf(data[\"gdf\"], layer_name=dataset, style=style)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1becf2-591e-424c-9f83-f3890f65d370",
   "metadata": {},
   "source": [
    "## Display available OPERA products at the selected Area of Interest (AOI) and Time of interest (TOI)\n",
    "* Now, we retrieve OPERA products available for this AOI at the time interval of interest (TOI) defined above by the user.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c42ba-6a0d-4db9-9052-6ee9bd4846d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the period the user selected above, we define the four dates/times below. \n",
    "StartDate_PreEvent = PreEventDate + \"T00:00:00\"  #Pre-event image start date\n",
    "EndDate_PreEvent = PreEventDate + \"T23:59:59\"    #Pre-event image end date\n",
    "\n",
    "StartDate_SynEvent = SynEventDate + \"T00:00:00\"  #Syn-event image start date\n",
    "EndDate_SynEvent= SynEventDate + \"T23:59:59\"    #Syn-event image end date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251d2b2-7e47-4886-aa80-33a252a85d2d",
   "metadata": {},
   "source": [
    "#### Query the OPERA DSWx-HLS dataset for the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09753e0-ec39-4885-a5d1-7ce5913f1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dswx_results_PreEvent, dswx_gdf_PreEvent = leafmap.nasa_data_search(\n",
    "        short_name='OPERA_L3_DSWX-HLS_V1',\n",
    "        cloud_hosted=True,\n",
    "        bounding_box= AOI,\n",
    "        temporal=(StartDate_PreEvent, EndDate_PreEvent),\n",
    "        count=-1,  # use -1 to return all datasets\n",
    "        return_gdf=True,\n",
    "    )\n",
    "    dswx_results_SynEvent, dswx_gdf_SynEvent = leafmap.nasa_data_search(\n",
    "        short_name='OPERA_L3_DSWX-HLS_V1',\n",
    "        cloud_hosted=True,\n",
    "        bounding_box= AOI,\n",
    "        temporal=(StartDate_SynEvent, EndDate_SynEvent),\n",
    "        count=-1,  # use -1 to return all datasets\n",
    "        return_gdf=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error fetching {'OPERA_L3_DSWX-HLS_V1'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedfc88-fc4a-4611-8ad1-84f0471b10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_results_PreEvent[0] #Note this just shows a single MGRS/HLS tile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5db5f3-0671-4a29-93c6-eab9ec3f80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_results_SynEvent[0] #Note this just shows a single MGRS/HLS tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924629b-2f8a-450b-8fd3-8476390efcf3",
   "metadata": {},
   "source": [
    "### View the DSWx-HLS metadata and footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548afc03-ea2f-420e-8098-257b11ded2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_gdf_PreEvent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a915da-52bc-4c3a-abca-6247cd61b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the location of the tiles \n",
    "#dswx_gdf_PreFlood.explore(fill=False)\n",
    "m_HLS = leafmap.Map(center=(c_lat, c_lon), zoom=5)\n",
    "style = { \"color\": \"blue\",        # Line color\n",
    "        \"weight\": 2,            # Line thickness\n",
    "        \"fillOpacity\": 0.0      # Transparent fill\n",
    "        }\n",
    "m_HLS.add_gdf(dswx_gdf_PreEvent, layer_name=\"DSWX Pre-Event\", style=style)\n",
    "m_HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d501a57-c92b-4721-8cf5-bb9416d9989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the location of the tiles \n",
    "#dswx_gdf_SynEvent.explore(fill=False)\n",
    "m_S1 = leafmap.Map(center=(c_lat, c_lon), zoom=5)\n",
    "m_S1.add_gdf(dswx_gdf_SynEvent, layer_name=\"DSWX Syn-Event\", style=style)\n",
    "m_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f4fbd-2e7f-48e3-813c-e8be900e238f",
   "metadata": {},
   "source": [
    "### Query the OPERA DSWx-S1 dataset for the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dae0d5-d6f0-4b2c-8bf9-f7e919ef191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dswx_results_PreEvent_S1V1, dswx_gdf_PreEvent_S1V1 = leafmap.nasa_data_search(\n",
    "        short_name='OPERA_L3_DSWX-S1_V1',\n",
    "        cloud_hosted=True,\n",
    "        bounding_box= AOI,\n",
    "        temporal=(StartDate_PreEvent, EndDate_PreEvent),\n",
    "        count=-1,  # use -1 to return all datasets\n",
    "        return_gdf=True,\n",
    "    )\n",
    "    \n",
    "    dswx_results_SynEvent_S1V1, dswx_gdf_SynEvent_S1V1 = leafmap.nasa_data_search(\n",
    "        short_name='OPERA_L3_DSWX-S1_V1',\n",
    "        cloud_hosted=True,\n",
    "        bounding_box= AOI,\n",
    "        temporal=(StartDate_SynEvent, EndDate_SynEvent),\n",
    "        count=-1,  # use -1 to return all datasets\n",
    "        return_gdf=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error fetching {'OPERA_L3_DSWX-S1_V1'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9a6b8-7c25-4cac-9ef6-17b854934284",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dswx_results_PreEvent_S1V1' in locals():\n",
    "    dswx_results_PreEvent_S1V1[0] #Note this just shows a single MGRS/HLS tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e25c4-38fc-4431-8e56-0518f6d9f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dswx_results_SynEvent_S1V1' in locals():\n",
    "    dswx_results_SynEvent_S1V1[0] #Note this just shows a single MGRS/HLS tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ba418-572e-4651-b40e-674dd7812640",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dswx_gdf_PreEvent_S1V1' in locals():\n",
    "    dswx_gdf_PreEvent_S1V1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81023adb-5ed5-4980-b710-a6356c9a08b0",
   "metadata": {},
   "source": [
    "*******************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2c1f7-0b35-4ad7-9c8a-9276a2341821",
   "metadata": {},
   "source": [
    "## Searching and Visualizing NASA OPERA Data Products Interactively \n",
    "* Another option is available through an Earthdata login. You can register for an account at urs.earthdata.nasa.gov. \n",
    "* For further information please refer to https://leafmap.org/notebooks/101_nasa_opera/\n",
    "* Run the Jupyter Notebook until this cell, before using the option below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c1c42-7c18-4464-9f64-d4793bf01ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leafmap.nasa_data_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9201b-8175-4cb8-a269-be535b492596",
   "metadata": {},
   "source": [
    "The map is zoomed in on the defined AOI. Select a dataset from the Short Name dropdown list. Click the \"Search\" button to load the available datasets for the region. The footprints of the datasets will be displayed on the map. Click on a footprint to display the metadata of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f50e1a-9ce3-43e8-b1a5-9de7381c1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map(center=(c_lat, c_lon), zoom=8, height=\"700px\")\n",
    "m.add_basemap(\"Satellite\")\n",
    "m.add(\"NASA_OPERA\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510fd0b-94ba-4361-a6fa-cad1736582c3",
   "metadata": {},
   "source": [
    "The footprints of the datasets can be accessed as a GeoPandas GeoDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1129484-676c-4d03-87ef-94e58200eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "m._NASA_DATA_GDF.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
